<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Brain AI - Control Center</title>
    <style>
        :root {
            --bg-primary: #0f0f1a;
            --bg-secondary: #1a1a2e;
            --bg-card: #16213e;
            --accent: #e94560;
            --accent-hover: #ff6b6b;
            --text: #eaeaea;
            --text-dim: #8892b0;
            --success: #00d26a;
            --warning: #ffc107;
            --error: #ff4757;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', system-ui, sans-serif;
            background: var(--bg-primary);
            color: var(--text);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            text-align: center;
            padding: 30px 0;
            border-bottom: 1px solid var(--bg-card);
            margin-bottom: 30px;
        }
        
        h1 {
            font-size: 2.5em;
            background: linear-gradient(135deg, var(--accent), #a855f7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: var(--text-dim);
            font-size: 1.1em;
        }
        
        .status-bar {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin-top: 20px;
            flex-wrap: wrap;
        }
        
        .status-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 8px 16px;
            background: var(--bg-secondary);
            border-radius: 20px;
            font-size: 0.9em;
        }
        
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }
        
        .status-dot.online { background: var(--success); }
        .status-dot.offline { background: var(--error); animation: none; }
        .status-dot.loading { background: var(--warning); }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .card {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 20px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .card:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(233, 69, 96, 0.2);
        }
        
        .card h3 {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
            color: var(--accent);
        }
        
        .card p {
            color: var(--text-dim);
            font-size: 0.9em;
            margin-bottom: 15px;
        }
        
        .btn {
            display: inline-block;
            padding: 10px 20px;
            background: var(--accent);
            color: white;
            text-decoration: none;
            border-radius: 6px;
            border: none;
            cursor: pointer;
            font-size: 0.9em;
            transition: background 0.2s;
        }
        
        .btn:hover {
            background: var(--accent-hover);
        }
        
        .btn-secondary {
            background: var(--bg-secondary);
            border: 1px solid var(--accent);
        }
        
        /* Chat Section */
        .chat-section {
            background: var(--bg-card);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 30px;
        }
        
        .chat-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        
        .model-select {
            padding: 8px 12px;
            background: var(--bg-secondary);
            border: 1px solid var(--accent);
            border-radius: 6px;
            color: var(--text);
            font-size: 0.9em;
        }
        
        .chat-messages {
            height: 300px;
            overflow-y: auto;
            padding: 15px;
            background: var(--bg-primary);
            border-radius: 8px;
            margin-bottom: 15px;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 10px 15px;
            border-radius: 8px;
            max-width: 80%;
        }
        
        .message.user {
            background: var(--accent);
            margin-left: auto;
        }
        
        .message.assistant {
            background: var(--bg-secondary);
        }
        
        .chat-input {
            display: flex;
            gap: 10px;
        }
        
        .chat-input input {
            flex: 1;
            padding: 12px 15px;
            background: var(--bg-primary);
            border: 1px solid var(--bg-secondary);
            border-radius: 8px;
            color: var(--text);
            font-size: 1em;
        }
        
        .chat-input input:focus {
            outline: none;
            border-color: var(--accent);
        }
        
        /* Model Cards */
        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
        }
        
        .model-card {
            background: var(--bg-secondary);
            border-radius: 8px;
            padding: 15px;
            cursor: pointer;
            transition: all 0.2s;
            border: 2px solid transparent;
        }
        
        .model-card:hover {
            border-color: var(--accent);
        }
        
        .model-card.active {
            border-color: var(--success);
            background: rgba(0, 210, 106, 0.1);
        }
        
        .model-card h4 {
            margin-bottom: 5px;
        }
        
        .model-card .size {
            font-size: 0.8em;
            color: var(--text-dim);
        }
        
        .model-card .status {
            font-size: 0.8em;
            margin-top: 8px;
        }
        
        /* Footer */
        footer {
            text-align: center;
            padding: 20px;
            color: var(--text-dim);
            font-size: 0.9em;
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            h1 { font-size: 1.8em; }
            .grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üß† Brain AI</h1>
            <p class="subtitle">Local AI Control Center | Pop!_OS ‚Ä¢ AMD RX 7900 XT ‚Ä¢ 128GB RAM</p>
            
            <div class="status-bar">
                <div class="status-item">
                    <span class="status-dot" id="vllm-status"></span>
                    <span>vLLM</span>
                </div>
                <div class="status-item">
                    <span class="status-dot" id="ollama-status"></span>
                    <span>Ollama</span>
                </div>
                <div class="status-item">
                    <span class="status-dot" id="webui-status"></span>
                    <span>Open WebUI</span>
                </div>
                <div class="status-item">
                    <span class="status-dot" id="whisper-status"></span>
                    <span>Whisper</span>
                </div>
            </div>
        </header>
        
        <!-- Quick Chat -->
        <section class="chat-section">
            <div class="chat-header">
                <h3>üí¨ Quick Chat</h3>
                <select class="model-select" id="model-selector">
                    <option value="vllm">vLLM (Primary)</option>
                    <option value="ollama">Ollama</option>
                </select>
            </div>
            
            <div class="chat-messages" id="chat-messages">
                <div class="message assistant">
                    Hello! I'm your local AI assistant running on Brain AI. How can I help you today?
                </div>
            </div>
            
            <div class="chat-input">
                <input type="text" id="chat-input" placeholder="Type a message..." onkeypress="if(event.key==='Enter')sendMessage()">
                <button class="btn" onclick="sendMessage()">Send</button>
            </div>
        </section>
        
        <!-- Services Grid -->
        <section class="grid">
            <div class="card">
                <h3>üåê Open WebUI</h3>
                <p>Full-featured chat interface with RAG, web search, and multi-model support.</p>
                <a href="http://localhost:3000" target="_blank" class="btn">Open Chat UI</a>
            </div>
            
            <div class="card">
                <h3>üìö AnythingLLM</h3>
                <p>Document RAG workspace. Upload files and chat with your data.</p>
                <a href="http://localhost:3001" target="_blank" class="btn">Open RAG</a>
            </div>
            
            <div class="card">
                <h3>üîç SearXNG</h3>
                <p>Private meta search engine for AI-powered web research.</p>
                <a href="http://localhost:8888" target="_blank" class="btn">Open Search</a>
            </div>
            
            <div class="card">
                <h3>üê≥ Portainer</h3>
                <p>Docker container management and monitoring dashboard.</p>
                <a href="https://localhost:9443" target="_blank" class="btn">Open Portainer</a>
            </div>
            
            <div class="card">
                <h3>üè† Home Assistant</h3>
                <p>Connect to your smart home with voice-enabled AI assistant.</p>
                <a href="http://homeassistant.local:8123" target="_blank" class="btn">Open HA</a>
            </div>
            
            <div class="card">
                <h3>üìä API Endpoints</h3>
                <p>Direct API access for integrations and testing.</p>
                <a href="http://localhost:8000/docs" target="_blank" class="btn">vLLM API</a>
                <a href="http://localhost:11434" target="_blank" class="btn btn-secondary" style="margin-left:5px">Ollama</a>
            </div>
        </section>
        
        <!-- Model Launcher -->
        <section class="card">
            <h3>üöÄ Model Launcher</h3>
            <p>Click a model to load it in vLLM. Only one model runs at a time.</p>
            
            <div class="model-grid" id="model-grid">
                <div class="model-card" onclick="loadModel('cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b')">
                    <h4>üê¨ Dolphin 12B</h4>
                    <span class="size">12B params ‚Ä¢ Uncensored</span>
                    <div class="status">Best for: Creative, experimental</div>
                </div>
                
                <div class="model-card" onclick="loadModel('huihui-ai/Phi-4-abliterated')">
                    <h4>‚ö° Phi-4 Abliterated</h4>
                    <span class="size">14B params ‚Ä¢ Uncensored</span>
                    <div class="status">Best for: Smart, unrestricted</div>
                </div>
                
                <div class="model-card" onclick="loadModel('TheBloke/WizardLM-13B-Uncensored-GPTQ')">
                    <h4>üßô WizardLM 13B</h4>
                    <span class="size">13B GPTQ ‚Ä¢ Uncensored</span>
                    <div class="status">Best for: Roleplay, erotica</div>
                </div>
                
                <div class="model-card" onclick="loadModel('huihui-ai/gemma-3-27b-it-abliterated-AWQ')">
                    <h4>üíé Gemma3 27B AWQ</h4>
                    <span class="size">27B AWQ ‚Ä¢ Abliterated</span>
                    <div class="status">Best for: Large context, quality</div>
                </div>
                
                <div class="model-card" onclick="loadModel('NousResearch/Hermes-3-Llama-3.1-8B')">
                    <h4>üîß Hermes 3 8B</h4>
                    <span class="size">8B params ‚Ä¢ Tool calling</span>
                    <div class="status">Best for: Home Assistant</div>
                </div>
                
                <div class="model-card" onclick="loadModel('Qwen/Qwen2.5-7B-Instruct')">
                    <h4>üéØ Qwen 2.5 7B</h4>
                    <span class="size">7B params ‚Ä¢ Fast</span>
                    <div class="status">Best for: General use, coding</div>
                </div>
            </div>
        </section>
        
        <!-- Wyoming / Home Assistant Section -->
        <section class="card" style="margin-top: 20px;">
            <h3>üé§ Voice Assistant (Wyoming)</h3>
            <p>Connect Home Assistant Voice Preview Edition to these endpoints:</p>
            
            <div style="background: var(--bg-primary); padding: 15px; border-radius: 8px; margin-top: 15px; font-family: monospace;">
                <p><strong>Whisper (STT):</strong> <span id="host-ip">localhost</span>:10300</p>
                <p><strong>Piper (TTS):</strong> <span id="host-ip2">localhost</span>:10200</p>
                <p><strong>LLM API:</strong> http://<span id="host-ip3">localhost</span>:8000/v1</p>
            </div>
            
            <p style="margin-top: 15px; font-size: 0.9em; color: var(--text-dim);">
                In Home Assistant: Settings ‚Üí Voice Assistants ‚Üí Add Wyoming Protocol integration
            </p>
        </section>
        
        <footer>
            <p>Brain AI v2.0 | Local-first AI Infrastructure</p>
            <p style="margin-top: 5px;">vLLM ‚Ä¢ Ollama ‚Ä¢ Open WebUI ‚Ä¢ Wyoming ‚Ä¢ Home Assistant</p>
            <p style="margin-top: 5px; font-size: 0.85em; color: var(--text-dim);">
                Ollama (11434) and Open WebUI (3000) run on the host with default ports.
            </p>
        </footer>
    </div>
    
    <script>
        // Configuration
        const VLLM_URL = 'http://localhost:8000';
        const OLLAMA_URL = 'http://localhost:11434';
        const WEBUI_URL = 'http://localhost:3000';
        const WHISPER_URL = 'http://localhost:10300';
        
        // Check service status
        async function checkStatus(url, elementId) {
            const dot = document.getElementById(elementId);
            dot.className = 'status-dot loading';
            
            try {
                const response = await fetch(url, { 
                    method: 'GET',
                    mode: 'no-cors',
                    cache: 'no-cache'
                });
                dot.className = 'status-dot online';
            } catch (e) {
                // Try with timeout
                try {
                    const controller = new AbortController();
                    const timeout = setTimeout(() => controller.abort(), 2000);
                    await fetch(url, { signal: controller.signal, mode: 'no-cors' });
                    clearTimeout(timeout);
                    dot.className = 'status-dot online';
                } catch {
                    dot.className = 'status-dot offline';
                }
            }
        }
        
        // Initialize status checks
        function initStatusChecks() {
            checkStatus(VLLM_URL + '/health', 'vllm-status');
            checkStatus(OLLAMA_URL + '/api/tags', 'ollama-status');
            checkStatus(WEBUI_URL + '/health', 'webui-status');
            checkStatus('http://localhost:10300', 'whisper-status');
            
            // Refresh every 30 seconds
            setInterval(() => {
                checkStatus(VLLM_URL + '/health', 'vllm-status');
                checkStatus(OLLAMA_URL + '/api/tags', 'ollama-status');
            }, 30000);
        }
        
        // Send chat message
        async function sendMessage() {
            const input = document.getElementById('chat-input');
            const messages = document.getElementById('chat-messages');
            const selector = document.getElementById('model-selector');
            const text = input.value.trim();
            
            if (!text) return;
            
            // Add user message
            messages.innerHTML += `<div class="message user">${escapeHtml(text)}</div>`;
            input.value = '';
            messages.scrollTop = messages.scrollHeight;
            
            // Determine endpoint
            const isVllm = selector.value === 'vllm';
            const url = isVllm ? VLLM_URL + '/v1/chat/completions' : OLLAMA_URL + '/api/chat';
            
            try {
                let response;
                if (isVllm) {
                    response = await fetch(url, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            model: 'default',
                            messages: [{ role: 'user', content: text }],
                            max_tokens: 500
                        })
                    });
                    const data = await response.json();
                    const reply = data.choices?.[0]?.message?.content || 'No response';
                    messages.innerHTML += `<div class="message assistant">${escapeHtml(reply)}</div>`;
                } else {
                    response = await fetch(url, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            model: 'llama3.2:latest',
                            messages: [{ role: 'user', content: text }],
                            stream: false
                        })
                    });
                    const data = await response.json();
                    const reply = data.message?.content || 'No response';
                    messages.innerHTML += `<div class="message assistant">${escapeHtml(reply)}</div>`;
                }
            } catch (e) {
                messages.innerHTML += `<div class="message assistant" style="color: var(--error)">Error: ${e.message}. Is the service running?</div>`;
            }
            
            messages.scrollTop = messages.scrollHeight;
        }
        
        // Load model in vLLM (requires server restart)
        function loadModel(modelId) {
            const confirmed = confirm(
                `Load model: ${modelId}?\n\n` +
                `This will update the vLLM configuration.\n` +
                `You'll need to restart vLLM for changes to take effect:\n\n` +
                `~/brain-ai/vllm-server.sh restart`
            );
            
            if (confirmed) {
                alert(
                    `To load this model:\n\n` +
                    `1. Edit ~/brain-ai/.env\n` +
                    `2. Set: VLLM_MODEL=${modelId}\n` +
                    `3. Run: ~/brain-ai/vllm-server.sh restart\n\n` +
                    `Model will download automatically if not cached.`
                );
            }
        }
        
        // Escape HTML
        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }
        
        // Get host IP for Wyoming config
        function updateHostIp() {
            // Use window location or fallback
            const host = window.location.hostname || 'localhost';
            document.querySelectorAll('[id^="host-ip"]').forEach(el => {
                el.textContent = host === 'localhost' ? '192.168.1.9' : host;
            });
        }
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            initStatusChecks();
            updateHostIp();
        });
    </script>
</body>
</html>
