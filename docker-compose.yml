################################################################################
#  BRAIN AI STACK - Portainer Edition v2
#  Pop!_OS 24.04 | Intel Ultra 7 265F | AMD RX 7900 XT (20GB) | 128GB RAM
#
#  vLLM runs BARE METAL (port 8000) - this stack connects to it
#  Deploy via: Portainer > Stacks > Add Stack > Upload
################################################################################

networks:
  brain-network:
    driver: bridge

volumes:
  ollama_data:
  openwebui_data:
  anythingllm_data:
  qdrant_data:
  searxng_data:
  whisper_data:
  piper_data:

services:
  #============================================================================
  # OLLAMA - Secondary LLM Inference (AMD GPU)
  # Used for embeddings and smaller models while vLLM handles main inference
  #============================================================================
  ollama:
    image: ollama/ollama:rocm
    container_name: brain_ollama
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.0.0
      - HIP_VISIBLE_DEVICES=0
      - ROCR_VISIBLE_DEVICES=0
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-2}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-1}
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    ipc: host
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  #============================================================================
  # OPEN WEBUI - Primary Chat Interface
  # Connects to BOTH vLLM (bare metal) and Ollama (docker)
  #============================================================================
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: brain_openwebui
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${WEBUI_PORT:-3000}:8080"
    volumes:
      - openwebui_data:/app/backend/data
    environment:
      # Ollama connection (docker container)
      - OLLAMA_BASE_URL=http://ollama:11434
      # vLLM connection (bare metal on host port 8000)
      - OPENAI_API_BASE_URL=http://host.docker.internal:${VLLM_PORT:-8000}/v1
      - OPENAI_API_KEY=sk-no-key-needed
      - ENABLE_OPENAI_API=true
      # UI Settings
      - WEBUI_AUTH=${WEBUI_AUTH:-false}
      - ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
      - DEFAULT_MODELS=${DEFAULT_MODELS:-}
      - WEBUI_NAME=Brain AI
      # RAG with SearXNG
      - ENABLE_RAG_WEB_SEARCH=true
      - RAG_WEB_SEARCH_ENGINE=searxng
      - SEARXNG_QUERY_URL=http://searxng:8080/search?q=<query>
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  #============================================================================
  # ANYTHINGLLM - RAG & Document Processing
  #============================================================================
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: brain_anythingllm
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${ANYTHINGLLM_PORT:-3001}:3001"
    volumes:
      - anythingllm_data:/app/server/storage
    environment:
      - STORAGE_DIR=/app/server/storage
      # Use vLLM as primary LLM
      - LLM_PROVIDER=openai
      - OPENAI_BASE_PATH=http://host.docker.internal:${VLLM_PORT:-8000}/v1
      - OPENAI_API_KEY=sk-no-key-needed
      - OPENAI_MODEL_PREF=dolphin-2.9.3-mistral-nemo-12b
      # Embeddings via Ollama
      - EMBEDDING_ENGINE=ollama
      - EMBEDDING_BASE_PATH=http://ollama:11434
      - EMBEDDING_MODEL_PREF=nomic-embed-text:latest
      # Vector DB
      - VECTOR_DB=qdrant
      - QDRANT_ENDPOINT=http://qdrant:6333
    extra_hosts:
      - "host.docker.internal:host-gateway"
    cap_add:
      - SYS_ADMIN
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  #============================================================================
  # QDRANT - Vector Database for RAG
  #============================================================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: brain_qdrant
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${QDRANT_HTTP_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  #============================================================================
  # SEARXNG - Private Search Engine
  #============================================================================
  searxng:
    image: searxng/searxng:latest
    container_name: brain_searxng
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${SEARXNG_PORT:-8888}:8080"
    volumes:
      - searxng_data:/etc/searxng
    environment:
      - SEARXNG_BASE_URL=http://localhost:${SEARXNG_PORT:-8888}
      - INSTANCE_NAME=Brain Search
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  #============================================================================
  # WHISPER - Speech to Text (for Home Assistant Wyoming)
  #============================================================================
  whisper:
    image: rhasspy/wyoming-whisper:latest
    container_name: brain_whisper
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${WHISPER_PORT:-10300}:10300"
    volumes:
      - whisper_data:/data
    command: 
      - "--model"
      - "small-int8"
      - "--language"
      - "en"
      - "--beam-size"
      - "1"
      - "--device"
      - "cpu"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10300"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  #============================================================================
  # PIPER - Text to Speech (for Home Assistant Wyoming)
  #============================================================================
  piper:
    image: rhasspy/wyoming-piper:latest
    container_name: brain_piper
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${PIPER_PORT:-10200}:10200"
    volumes:
      - piper_data:/data
    command:
      - "--voice"
      - "en_US-lessac-medium"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10200"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  #============================================================================
  # HOMEPAGE - Dashboard Launcher
  #============================================================================
  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: brain_homepage
    restart: unless-stopped
    networks:
      - brain-network
    ports:
      - "${HOMEPAGE_PORT:-80}:3000"
    volumes:
      - ./homepage:/app/config
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - PUID=1000
      - PGID=1000
